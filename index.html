<!DOCTYPE html><html>
<head>
<meta name="viewport" content="width=device-width, height=device-height, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<script src="all.js"></script>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(["_setAccount", "UA-15384464-1"]);
  _gaq.push(["_trackPageview"]);

  (function() {
   var ga = document.createElement("script"); ga.type = "text/javascript"; ga.async = true;
   ga.src = ("https:" == document.location.protocol ? "https://ssl" : "http://www") + ".google-analytics.com/ga.js";
   var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(ga, s);
   })();
</script>
<style>
  body {
  background: #444;
  background-color: #444;
  }

  img {
  border:0px solid #eaeaea;
  padding: 0p;
  }

  table {
  width:100%;
  max-width:  100%;
  overflow: hidden;
  table-layout: fixed;
  }

  td {
  width: 30%;
  max-width: 300px;
  }

  .box {
  display: inline-block;
  width: 300px;
  padding: 10px;
  position: relative;
  text-align: left;
  padding: 10px 10px 10px 10px;
  cursor: pointer;
  }
  .boxpad {
  height:  0px;
  padding: 0px 10px 0px 10px;
  }

  .crop {
  width: 100%;
  max-width: 300px;
  height: 160px;
  overflow: hidden;
  }

  .coverimg {
  height: 200px;
  width: auto;
  margin: -20px 0 0 0px;
  }

  .coverimg-auto {
  height: 30em;
  margin: -15em 0 0 0px;
  }

  .hidden {
  display: none;
  }

  a:link {color:#CCCCCC; text-decoration:none; }      /* unvisited link */
  a:visited {color:#CCCCCC; text-decoration:none; }  /* visited link */
  a:hover {color:#EEEEEE; text-decoration:underline; }  /* mouse over link */
  a:active {color:#eaeaea; text-decoration:underline; }  /* selected link */

  p,div {
  font-size: 0.99em;
  font-family: "Gill Sans", "Century Gothic", "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;
  color: #eaeaea;
  }

  div {
  border-width: 1px;
  border-color: #000000;
  }

  .reel {
  position:absolute;
  top: 0px;
  left: 10%;
  width: 80%;
  height: 100%;
  }

  .reelmobile {
  top: 0px;
  left: 0px;
  width: 100%;
  height: 100%;
  }


  #header {
  position: relative;
  padding-top: 10px;
  padding-bottom: 20px;
  padding-left: 0px;
  left: 0%;
  width: 100%;
  }

  #leftheader {
  position: relative;
  left: 0px;
  }

  #rightheader {
  position: relative;
  top: 0px;
  margin-top: 10px;
  right: 0px;
  }

  #toplevel {
  display: none;
  position: relative;
  top:  8%;
  text-align: center;
  }

  #menu {
  position: relative;
  top: 0px;
  -webkit-transition: visibility 0.4s ease-in-out;
  transition: visibility  0.4s ease-in-out;
  text-align: center;
  }

  #spinner {
  position: fixed;
  top: 50%;
  left: 50%;
  border:  3px solid #f3f3f3;
  border-top:    3px solid rgba(255, 0, 0, 0.0);
  border-bottom:    3px solid rgba(255, 0, 0, 0.0);
  border-radius: 50%;
  margin-top: -15px;
  margin-left: -15px;
  width:  30px;
  height:  30px;
  animation: spin 2s linear infinite;
  }

  @keyframes spin {
  0% { transform: rotate(0deg); }
  100% { transform: rotate(360deg); }
  }

  #topleveltable {
  }

  #projects {
  display: none;
  }

  .project {
  display: block;
  width: 100%;
  }

  .image {
  display: inline-block;
  border:0px solid #eaeaea;
  width:  48%;
  margin-right: 1%;
  margin-bottom: 0.5em;
  vertical-align: top;
  }

  .wide {
  width:   97%;
  }

  .desctitle {
  font-size:  100%;
  /*font-weight: bold;*/
  }

  .descmedia {
  font-style: italic;
  }

  .descyear{
  font-style: italic;
  }

  .desctext{
  padding-top: 20px;
  padding-bottom: 20px;
  }

  hr {
  margin-top: 25px;
  margin-bottom: 25px;
  }
</style>
</head>
<body>
  <div id="reel" class="reel" onload="interpretUrlState()">
    <div id="header">
      <div id="leftheader">
        <a href="?"><img src="pics/miketyka.png" id="miketyka"></a>
      </div>
      <div id="rightheader">
       <a href="https://www.twitter.com/mtyka" target="_blank">Twitter</a> -
       <a href="https://www.instagram.com/miketyka" target="_blank">Instagram</a> -
       <a href="https://www.github.com/mtyka" target="_blank">GitHub</a> -
       <a href="https://mtyka.github.io" target="_blank">Blog</a> -
       <a href="?p=bio">Bio</a> -
       <a href="?p=contact">Contact</a>
     </div>
   </div>
   <div id="spinner">
   </div>
   <div id="toplevel">
    <hr>
    <div id="topleveltable">
    </div>
    <hr>
  </div>

  <div id="menu" class="hidden">
    <hr>
    <div id="menutable">
    </div>
    <hr>
  </div>


  <!-- ======= ======= ======= ======= ======= ======= ======= ======= ======= ======= ======= ======= ======= ======= -->
  <div id="projects">

    <div class="project copper molecule" id="ubiquitin" >
      <img src="projects/ubiquitin.jpg" class="coverimg hidden">
      <div class="desctitle">"Angel of Death" - Ubiquitin</div>
      <div class="descmedia">Copper, Steel -  9"x9"x16"</div>
      <div class="descyear">2011</div>
      <div class="imagebox">
        <hr>
        <img data-src="projects/ubiquitin/ubiquitin_5_big.jpg" class="image">
        <div class="desctext image">
          <img data-src="projects/ubiquitin/ubiquitin_6_big.jpg" class="image wide">
          <br>Life is a dynamic equilibrium of creation and destruction. Inside our cells the protein nano-machines, to which we owe our distinction from the inorganic, are perpetually recycled and rebuilt, forever battling the inevitable fate of entropic decay. Once covalently tagged with Ubiquitin, a protein is doomed to destruction by the proteasome, a protein degradation machine found in all of our cells. The component amino acids are then reused to synthesize new proteins. The constant recycling and rebuilding of proteins not only ensures that damaged proteins are removed quickly, but also allows rapid regulation of enzyme levels in the cell. The meandering path of the metal ribbon closely follows the fold and thus the internal structure of Ubiquitin. It features all of the major structural elements of typical proteins, including two alpha helices and a curved beta sheet. Its small size (76 amino acids) makes it one of the most studied proteins for protein folding and dynamics.
        </div>
        <hr>
        <img data-src="projects/ubiquitin/ubiquitin_3_big.jpg" class="image">
        <img data-src="projects/ubiquitin/ubiquitin_7_big.jpg" class="image">
        <hr>
      </div>
    </div>

    <div class="project copper molecule" id="tears" >
      <img src="projects/tears.jpg" class="coverimg hidden">
      <div class="desctitle">"Tears" - Lysozyme with carbohydrate</div>
      <div class="descmedia">Cast bronze, Cast Glass, Wood - 20"x10"x12"</div>
      <div class="descyear">2015</div>
      <hr>
      <div class="imagebox">
        <img data-src="projects/tears/DSC_6266_rot_crop.jpg" class="image wide">
      </div>
      <div class="desctext">
        <hr>
        Tears display antibacterial activity, a property that was discovered by Alexander Fleming around the turn of the last century. The active agent, Lysozyme, is also found in saliva, nasal mucus and even breast milk and constitutes a major element in the body&#39;s innate immune defense.
        Lysozyme was also one of the first proteins and the very first enzyme to have its three dimensional structure elucidated in the 60s through painstaking X-ray crystallography work by David Phillips. The coordinates obtained were used here to create the initial 3D model of the protein which was then 3D printed in plastic, post processed and then recast in clear lead glass using direct lost-PLA casting.
        Many bacteria implicated in human disease have a protective cell wall. Lysozyme is an enzyme which digests these carbohydrate barriers, thereby significantly weakening the potential intruders. The carbohydrate, part of which is cast here in bronze, fits tightly into the active site cleft of the Lysozyme enzyme. Deep inside that cleft the cleavage reaction takes place, catalysed by the protein. After cleavage Lysozyme releases both parts and moves on to a new cleavage site, gradually breaking down the cell wall. Discovery of the atom structure led to the first detailed enzymatic mechanism to be described and was a major breakthrough in our understanding of how our bodies&#39; metabolic functions.
        <hr>
      </div>
    </div>

    <div class="project copper molecule" id="porin" >
      <img src="projects/porin.jpg" class="coverimg hidden">
      <div class="desctitle">"Portal" - Bacterial Porin</div>
      <div class="descmedia">Copper, Steel, Wenge Wood - 12"x12"x24"</div>
      <div class="descyear">2012</div>
      <div class="desctext">
        <hr>
        The boundary of cellular life, which delineates the living chemistry from its surroundings, was among the most important fundamental inventions of evolution eons ago. Protein channels span these molecular castle walls and regulate the diffusional traffic of molecules trying to enter or leave the cell. One class of these molecular gatekeepers are the Porins, beta-barrel proteins that are situated in the outer membranes of cells or organelles such as human mitochondria. The Porin channel is partially blocked by a loop, called the eyelet, which projects into the cavity and defines the size of solute that can traverse the channel. Porins can be chemically selective, they can transport only one group of molecules, or may be specific to one molecule. For example, for antibiotics to be effective against a bacterium, it must often pass through an outer membrane Porin. Bacteria can develop resistance to the antibiotic by mutating the gene that encodes the Porin â€“  the antibiotic is then excluded from passing through the outer membrane. The scale used in this sculpture is 2.5 inch/nm (a magnification factor of 63 million). At this magnification a grain of rice would roughly span the distance between Seattle and Portland.
        <hr>
      </div>
      <div class="imagebox">
        <img data-src="projects/porin/porin_0_big.jpg" class="image">
        <!--<img data-src="projects/porin/porin_1_big.jpg" class="image">-->
        <img data-src="projects/porin/porin_3_big.jpg" class="image">
        <img data-src="projects/porin/porin_2_big.jpg" class="image">
        <img data-src="projects/porin/porin_4_big.jpg" class="image">
        <hr>
      </div>
    </div>

    <div class="project copper molecule" id="annealing" >
      <img src="projects/annealing.jpg" class="coverimg hidden">
      <div class="desctitle">The Annealing - DNA</div>
      <div class="descmedia">Cast glass, Cast bronze, Vera wood - 16"x9"x11"</div>
      <div class="descyear">2016</div>
      <div class="desctext">
        <hr>
        Two short complementary DNA strands have found each other and are annealing together to form one double-stranded DNA molecule. The ability of DNA to stick to itself in an extremely specific manner, like a programmable velcro, has been of great interest to research interested in developing nanomaterials. A huge variety of shapes, lattices, even small molecular machines can be constructed using DNA - the amazing thing is that the components can simply all be combined in solution and the structure builds itself. This has no equivalent in our macroscopic world. Throwing the parts of a kid&#39;s puzzle into a tumble dryer would hardly result in the puzzle being solved. Yet at the microscopic scale the rules are different. Proteins exhibit a similar ability to fold themselves and assemble into larger complexes. This sort of self assembly is at the base of life itself; its parts constantly self assemble into working nanomachines which catalyse and manipulate other parts of living cells.
      </div>

      <div class="imagebox">
        <hr>
        <img data-src="projects/annealing/img1sm.jpg" class="image">
        <img data-src="projects/annealing/img2.jpg" class="image">
        <hr>
        <img data-src="projects/annealing/img3.jpg" class="image">
        <img data-src="projects/annealing/img4.jpg" class="image">
        <hr>
      </div>
    </div>

    <div class="project copper molecule" id="kiss" >
      <img src="projects/kiss.jpg" class="coverimg hidden">
      <div class="desctext">
        <div class="desctitle">"Synaptic Kiss" - MHC and TCR</div>
      <div class="descmedia">Cast glass, Cast aluminum</div>
      <div class="descyear">2016</div>
      <hr>
        One of the most important parts of the human immune system is the interaction between the Major Histocompatibility Complex (MHC) and the T-Cell receptor.
        The MHC is found on the surface of normal cells and special antigen presenting cells. The MHC presents on its surface small peptides which are small digested bits of proteins. The T-Cell scans these presented fragments using its receptor looking for any fragment that might be foreign. If an unauthorized sequence is detected it indicates that an intruding organism has entered the body and an immune response is mounted against any other cells showing the same signature. This is particularly important in fighting viral infection. Since viruses do not have their own metabolism they are difficult tokill. Instead their replication cycle is interrupted by circulating T-cells actively killing human host cells which are infected (and will betray their infection using the MHC-TCR mechanism).
        There is a tight lock-and-key fit between MHC and TCR - a delicate and intimate interaction between two molecules whose surfaces are highly complementary. The peptide itself is cast in aluminum while the two partners, each composed from two separate subunits, are cast in glass.
        <hr>
      </div>
      <div class="imagebox">
        <img data-src="projects/kiss/img1.jpg" class="image">
        <img data-src="projects/kiss/img2.jpg" class="image">
        <hr>
        <img data-src="projects/kiss/img3.jpg" class="image">
        <img data-src="projects/kiss/img4.jpg" class="image">
        <hr>
      </div>
    </div>

    <div class="project copper molecule" id="savior" >
      <img src="projects/savior.jpg" class="coverimg hidden">
      <div class="desctitle">"Savior" - IgG</div>
      <div class="descmedia">Copper, Steel, Gold/Chrome plating - 56"x50"x18"</div>
      <div class="descyear">2013</div>
      <div class="desctext">
        <hr>
        <img data-src="projects/savior/_MG_6105.jpg" class="image wide">
        The machinery of life, an inevitably complex system, must constantly defend itself from intrusion and subversion by other agents inhabiting the biosphere.  Ever more intricate systems for the detection and thwarting of intruding foreign life forms have evolved over the eons, culminating in adaptive immunity with one of its centerpieces: The Antibody. Also known as Immunoglobulin, this pronged, Y-shaped protein structure is capable of binding, blocking and neutralizing foreign objects such as as bacteria or viruses.
        The two tips of the Y have special patches which can tightly recognize and bind a target. Our body generates astronomical numbers of variants, each recognizing a different shape. The variety is so great that completely alien molecules can be recognized even though the body has never encountered them before. Once bound, the antibody blocks the function of the foreign object by physically occluding its functional parts. The Antibody sacrifices itself in the process but not before signalling to the immune system to make more of its specific variant form. After the intruder in question has been fought off, memory cells remain in the bloodstream that can quickly be reactivated should reinfection occur to produce more of the successful variant Antibody.
        <hr>
      </div>
      <div class="imagebox">
       <img data-src="projects/savior/DSC_8873_large.jpg" class="image wide">
       <hr>
       <img data-src="projects/savior/DSC_8931_large.jpg" class="image">
       <img data-src="projects/savior/DSC_8976_large.jpg" class="image">
       <hr>
       <img data-src="projects/savior/DSC_8977_large.jpg" class="image">
       <img data-src="projects/savior/DSC_8914_rotated_large.jpg" class="image">
       <!-- <hr> <img data-src="projects/savior/savior_2_big.jpg" class="image wide">-->
       <hr>
     </div>
   </div>


   <div class="project copper molecule" id= "dna1">
    <img src="projects/dna1.jpg" class="coverimg hidden">
    <div class="desctitle">DNA Study 1</div>
    <div class="descmedia">Cast lead glass, Steel- 9"x7"x4"</div>
    <div class="descyear">2015</div>
    <div class="imagebox">
      <hr>
      <img data-src="projects/dna1/dna1.jpg" class="image wide">
    </div>
    <div class="desctext">
      <hr>
      DNA, or deoxyribonucleic acid, is a two-stranded helical polymer which is used by virtually all known forms of life to encode genetic information. It is composed of repeating units called nucleotides of which there are four variants: Adenosine (A), Thymine (T),  Cytosine (C)  and Guanine (G). These are flat molecules which stack on top of each other like a set of double stairs, held together by a sugar-phosphate backbone which runs on the outside. This arrangement was famously discovered through work by Francis Crick, Rosalind Franklin, and James Watson. Critically, every A is paired with a T on the opposite strand and every G is paired with C. This means that each strand contains all the information needed to recreate the other, thus immediately suggesting a straightforward way in which the information could be copied. Indeed, during cell replication the strands separate and complex protein machinery rebuilds the opposite strand for each of the original single strands. Natural errors during this process lead to genetic drift and are a major component of the evolutionary forces that lead from the early simple organisms many billion years ago to the highly sophisticated ones found today.
      Shown here is a short section of double-stranded DNA (about 11 nucleotide units) which would be only 3.6 nanometers long in reality.
      <hr>
    </div>
  </div>



  <div class="project copper molecule" id="potassium" >
    <img src="projects/kcsa.jpg" class="coverimg hidden">
    <div class="desctitle">KcsA Potassium Channel</div>
    <div class="descmedia">Copper, Steel - 14"x14"x20"</div>
    <div class="descyear">2011</div>
    <div class="desctext">
      <hr>
      Potassium channels form potassium-selective pores that span cell membranes. They are the most widely distributed type of ion channel found in virtually all living organisms. The four identical subunits are situated in a four-fold symmetrical manner around a central pore, which allows potassium ions to pass freely.  At the top of the structure, formed by four loops lining the pore, a selectivity filter is situated which prevents other ions (such as sodium ions) from passing. The correct ions are detected by their size and charge. Note that that no active pumping of ions occurs; it merely allows passive conductance of ions down the con-centration gradient between the two sides of the membrane.
      The KcsA is an archetypal membrane protein with eight tightly packed membrane-spanning a-helices.  The four short helices in the center where the chain crosses half the membrane and then returns to the top are a more unusual feature.
      <hr>
    </div>
    <div class="imagebox">
     <img data-src="projects/kcsa/kcsa_5_big.jpg" class="image">
     <img data-src="projects/kcsa/kcsa_0_big.jpg" class="image">
     <img data-src="projects/kcsa/kcsa_4_big.jpg" class="image">
     <img data-src="projects/kcsa/kcsa_1_big.jpg" class="image">
     <img data-src="projects/kcsa/kcsa_2_big.jpg" class="image">
     <img data-src="projects/kcsa/kcsa_3_big.jpg" class="image">
     <hr>
   </div>
 </div>

 <div class="project copper molecule" id="prometheus" >
  <img src="projects/prometheus.jpg" class="coverimg hidden">
  <div class="desctitle">"Prometheus"</div>
  <div class="descmedia">Copper, Steel, Walnut, Gold - 10"x6"x6"</div>
  <div class="descyear">2014 - Series of 3, private collection</div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/prometheus/DSC_2836_cropped_sm.jpg" class="image wide">
  </div>
  <div class="desctext">
    <hr>
    It is a brave new world, moving from our mechanical world, born in the industrial revolution, to the biotechnological future.
    The gears of life are complex, encoded polymers, nano machines that create order out of disorder and harness the free energy of the sun to perpetuate the information they carry in to the unknown. Now, man begins to alter that very microscopic machinery that constitutes his existence, that gives rise to his
    consciousness out of inorganic matter, ever driven forward by his curiosity and desire to manipulate his surroundings and himself.
    <hr>
  </div>
</div>


<div class="project copper molecule" id="whitechen" >
  <img src="projects/whitechen.jpg" class="coverimg hidden">
  <div class="desctitle">White-Chen catalyst</div>
  <div class="descmedia">Cast lead glass, Steel, Magnets - 14"x12"x12"</div>
  <div class="descyear">2015, private collection</div>
  <div class="desctext">
  </div>
  <div>
    <hr>
    <img data-src="projects/whitechen/DSC_4733_large.jpg" class="image wide">
    <img data-src="projects/whitechen/DSC_4699_large.jpg" class="image wide">
    <hr>
  </div>
</div>

<!-- DEEPDREAM -->

<div class="project digital deepdream" id="ankunft">
  <img src="projects/newdeepdreams/coverimg/Die_Ankunft(2016)_med.jpg" class="coverimg hidden">
  <div class="desctitle">Die Ankunft</div>
  <div class="descmedia">Neural net, Archival print, 36x60"</div>
  <div class="descyear">2016</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/newdeepdreams/Die_Ankunft(2016)_med.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream" id="birdsii">
  <img src="projects/newdeepdreams/coverimg/Birds_II(2016)_med.jpg" class="coverimg hidden">
  <div class="desctitle">Birds II</div>
  <div class="descmedia">Neural net, Archival print, 36x60"</div>
  <div class="descyear">2016</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/newdeepdreams/Birds_II(2016)_med.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream" id="redshift">
  <img src="projects/newdeepdreams/coverimg/Redshift(2016)_med.jpg" class="coverimg hidden">
  <div class="desctitle">Redshift</div>
  <div class="descmedia">Neural net, Archival print, 36x60"</div>
  <div class="descyear">2016</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/newdeepdreams/Redshift(2016)_med.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream" id="surrender">
  <img src="projects/newdeepdreams/coverimg/Surrender(2017)_med.jpg" class="coverimg hidden">
  <div class="desctitle">Surrender</div>
  <div class="descmedia">Neural net, Archival print, 36x60"</div>
  <div class="descyear">2017</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/newdeepdreams/Surrender(2017)_med.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream" id="theportal">
  <img src="projects/newdeepdreams/coverimg/ThePortal(2016)_med.jpg" class="coverimg hidden">
  <div class="desctitle">The Portal</div>
  <div class="descmedia">Neural net, Archival print, 36x60"</div>
  <div class="descyear">2016</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/newdeepdreams/ThePortal(2016)_med.jpg" class="image wide">
    <hr>
  </div>
</div>

<div class="project digital deepdream" id="CastlesInTheSkyWithDiamonds">
  <img src="projects/grayarea/coverimg/CastlesInTheSkyWithDiamonds.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">Castles In The Sky With Diamonds</div>
  <div class="descmedia">Neural net, Archival print, 60"x48", SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/CastlesInTheSkyWithDiamonds.jpg" class="image wide">
    <hr>
  </div>
</div>


<div class="project digital deepdream" id="HowWeEndUpAtTheEndOfLife">
  <img src="projects/grayarea/coverimg/HowWeEndUpAtTheEndOfLife.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">How We End Up At The End Of Life</div>
  <div class="descmedia">Neural net, Archival print, 60"x48", SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext">Title generated by LSTM by Ross Goodwin.
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/HowWeEndUpAtTheEndOfLife.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream" id="GodsBrigade">
  <img src="projects/grayarea/coverimg/GodsBrigade.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">Ground still state of God&rsquo;s original brigade</div>
  <div class="descmedia">Neural net, Archival print, 60"x48", SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext">Title generated by LSTM by Ross Goodwin.
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/GodsBrigade.jpg" class="image wide">
    <hr>
  </div>
</div>

<div class="project digital deepdream" id="CarboniferousFantasy">
  <img src="projects/grayarea/coverimg/CarboniferousFantasy.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">Carboniferous Fantasy</div>
  <div class="descmedia">Neural net, Archival print, 60"x48", SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/CarboniferousFantasy.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream" id="Jurogumo">
  <img src="projects/grayarea/coverimg/Jurogumo.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">Jurogumo</div>
  <div class="descmedia">Neural net, Archival print, 38"x31", SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/Jurogumo.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream" id="Mukade">
  <img src="projects/grayarea/coverimg/Mukade.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">Mukade</div>
  <div class="descmedia">Neural net, Archival print, 38"x31", SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/Mukade.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream" id="FabricOfMind">
  <img src="projects/grayarea/coverimg/FabricOfMind.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">Fabric Of Mind</div>
  <div class="descmedia">Neural net, Archival print 100"x48", SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/FabricOfMind.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream " id="TheBabylonOfTheBlueSun">
  <img src="projects/grayarea/coverimg/TheBabylonOfTheBlueSun.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">The Babylon Of The Blue Sun</div>
  <div class="descmedia">Neural net, Archival print, 66"x50", SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext">Title generated by LSTM by Ross Goodwin.
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/TheBabylonOfTheBlueSun.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream " id="TheFall">
  <img src="projects/grayarea/coverimg/TheFall.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">The Fall</div>
  <div class="descmedia">Neural net, Archival print, 71"x52", SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext">Title generated by LSTM by Ross Goodwin.
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/TheFall.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream" id="HereWasTheFinalBlindHour">
  <img src="projects/grayarea/coverimg/HereWasTheFinalBlindHour.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">Here Was The Final Blind Hour</div>
  <div class="descmedia">Neural net, Archival print, 74"x52", SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext">Title generated by LSTM by Ross Goodwin.
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/HereWasTheFinalBlindHour.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream" id="himalayas">
  <img src="projects/grayarea/coverimg/Himalayas.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">Himalayas</div>
  <div class="descmedia">Neural net, Lasercut wood, 30"x24"</div>
  <div class="descyear">2016</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/Himalayas.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream stillife" id="Bacchus">
  <img src="projects/grayarea/coverimg/Bacchus.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">Bacchus</div>
  <div class="descmedia">Neural net, Archival print, 11.75"x11.75" SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext">
	This piece is the result of two concepts an artificial neural network has learned about expressed simultaneously: Pitchers and Flowers. Together the form a blended new whole, though the combination has occured not in the space of pixels but in the semantic or latent space that is created beed inside the neural network.  
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/Bacchus.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream stillife" id="StyleIsViolins">
  <img src="projects/grayarea/coverimg/StyleIsViolins.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">Style Is Violins</div>
  <div class="descmedia">Neural net, Archival print, 21"x21", SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/StyleIsViolins.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream stillife" id="Cellism">
  <img src="projects/grayarea/coverimg/Cellism.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">Cellism</div>
  <div class="descmedia">Neural net, Archival print, 21"x21", SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext"> </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/Cellism.jpg" class="image wide">
    <hr>
  </div>
</div>
<div class="project digital deepdream stillife" id="SaxophoneDreams">
  <img src="projects/grayarea/coverimg/SaxophoneDreams.jpg.small.jpg" class="coverimg hidden">
  <div class="desctitle">Saxophone Dreams</div>
  <div class="descmedia">Neural net, Archival print, 21"x21", SOLD</div>
  <div class="descyear">2016</div>
  <div class="desctext"> </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/grayarea/SaxophoneDreams.jpg" class="image wide">
    <hr>
  </div>
</div>

<!-- INCEPTIONISM -->

<div class="project digital deepdream inceptionism" id="inceptionism1">
  <img src="projects/inceptionism/coverimg/Iterative_Places205-GoogLeNet_3.jpg.sm.jpg" class="coverimg hidden">
  <div class="desctitle">Inceptionism: Cities</div>
  <div class="descmedia">Neural net, digital (NOT AVAILABLE)</div>
  <div class="descyear">2015</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/inceptionism/Iterative_Places205-GoogLeNet_3.jpg.sm.jpg" class="image">
    <img data-src="projects/inceptionism/Iterative_Places205-GoogLeNet_4.jpg.sm.jpg" class="image">
    <img data-src="projects/inceptionism/Iterative_Places205-GoogLeNet_6.jpg.sm.jpg" class="image">
    <img data-src="projects/inceptionism/Iterative_Places205-GoogLeNet_15.jpg.sm.jpg" class="image">
    <hr>
  </div>
</div>

<div class="project digital deepdream inceptionism" id="inceptionism2">
  <img src="projects/inceptionism/coverimg/Iterative_Places205-GoogLeNet_17.jpg.sm.jpg" class="coverimg hidden">
  <div class="desctitle">Inceptionism: Patterns</div>
  <div class="descmedia">Neural net, digital, chance, (NOT AVAILABLE)</div>
  <div class="descyear">2015</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/inceptionism/Iterative_Places205-GoogLeNet_17.jpg.sm.jpg" class="image">
    <img data-src="projects/inceptionism/Iterative_Places205-GoogLeNet_2.jpg.sm.jpg" class="image">
    <img data-src="projects/inceptionism/Iterative_Places205-GoogLeNet_12.jpg.sm.jpg" class="image">
    <img data-src="projects/inceptionism/Iterative_Places205-GoogLeNet_10.jpg.sm.jpg" class="image">
    <hr>
  </div>
</div>

<div class="project digital deepdream inceptionism" id="inceptionism3">
  <img src="projects/inceptionism/coverimg/Iterative_Places205-GoogLeNet_18.jpg.sm.jpg" class="coverimg hidden">
  <div class="desctitle">Inceptionism: Landscapes</div>
  <div class="descmedia">Neural net, digital, chance, (NOT AVAILABLE)</div>
  <div class="descyear">2015</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/inceptionism/Iterative_Places205-GoogLeNet_18.jpg.sm.jpg" class="image">
    <img data-src="projects/inceptionism/Iterative_Places205-GoogLeNet_19.jpg.sm.jpg" class="image">
    <img data-src="projects/inceptionism/Iterative_Places205-GoogLeNet_20.jpg.sm.jpg" class="image">
    <img data-src="projects/inceptionism/Iterative_Places205-GoogLeNet_14.jpg.sm.jpg" class="image">
    <hr>
  </div>
</div>


<!-- FACES -->

<div class="project sculpture faces" id="usandthem">
  <img src="projects/usandthem/img_5130.jpg" class="coverimg hidden">
  <div class="desctitle">Us and Them</div>
  <div class="descmedia">Kinetic Installation</div>
  <div class="descyear">2018, Commissioned by Seoul Museum of Art</div>
  <div class="desctext">
 "Us and Them" is a multi-modal installation that combines the earlier <a href="http://www.miketyka.com/?s=faces">"Portraits of Imaginary People"</a> work with neural-net text generation and kinetic sculpture. Trained on a recently released set of two hundred thousand tweets from accounts identified as bots after the 2016 US presidential election and consequently evicted from Twitter, this piece features 20 machine-learning-driven printers which endlessly spew AI-generated political tweets by imaginary, generated people. The descending curtain of printer paper creates a central space with two chairs, inviting two people to sit, converse and connect, despite the torrent of machine-generated political propaganda that surrounds them. 
<br><br>  
  The piece examines our new world which we created, a digital attention economy, in which we're constantly distracted, digitally connected and yet yearning for human connection. A fertile ground for political manipulation, propaganda is now fully automated and targeted, using machine learning to analyse its targets while pretending to be human. Synthetic media, also thorough modern computer vision technology and neural networks, blurs the boundary between what is a real and what is not. Doublespeak, such as the term "fake news" is further used to undermine what we know is real while pushing intentionally misleading information on an unprecedented scale. 
   <br><br>
   "Us and Them" invites the viewer to reexamine their relationship with the machine we live inside and to seek true connection with one another.
   <br><br>
	 The 20 thermal receipt printers are live and continuously printing AI generated tweets at a slow but steady pace, letting this sculpture evolve and change every day. Ultimately the torrent overwhelm and bury the central space and chairs.
  </div>
  <div class="imagebox">
    <img data-src="projects/usandthem/img_5179.jpg" class="image wide">
    <img data-src="projects/usandthem/img_5130.jpg" class="image wide ">
    <img data-src="projects/usandthem/img_5085.jpg" class="image">
    <img data-src="projects/usandthem/img_5088.jpg" class="image">
    <img data-src="projects/usandthem/pic1.jpg" class="image">
    <img data-src="projects/usandthem/img_5136.jpg" class="image">
    <img data-src="projects/usandthem/img_5138.jpg" class="image">
    <img data-src="projects/usandthem/img_5083.jpg" class="image">
    <img data-src="projects/usandthem/img_5180.jpg" class="image">
    <img data-src="projects/usandthem/img_5137.jpg" class="image">
  </div>
</div>

<div class="project digital portraits faces" id="I see you">
  <img src="projects/faces/cover/I see you.jpg" class="coverimg hidden">
  <div class="desctitle">I see you</div>
  <div class="descmedia">Archival print, 20"x20", Edition of 2</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/I see you.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>



<div class="project digital portraits faces" id="A fleeting memory">
  <img src="projects/faces/cover/A fleeting memory.jpg" class="coverimg hidden">
  <div class="desctitle">A fleeting memory</div>
  <div class="descmedia">Archival print, 20"x20", Edition of 2</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/A fleeting memory.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="Blinovaexininta">
  <img src="projects/faces/cover/Blinovaexininta.jpg" class="coverimg hidden">
  <div class="desctitle">Blinovaexininta</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/Blinovaexininta.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="Elizabeth_Pr22">
  <img src="projects/faces/cover/Elizabeth_Pr22.jpg" class="coverimg hidden">
  <div class="desctitle">Elizabeth_Pr22</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/Elizabeth_Pr22.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="evegreene88">
  <img src="projects/faces/cover/evegreene88.jpg" class="coverimg hidden">
  <div class="desctitle">evegreene88</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/evegreene88.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="finley1589">
  <img src="projects/faces/cover/finley1589.jpg" class="coverimg hidden">
  <div class="desctitle">finley1589</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/finley1589.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="Gabrielitaa7x">
  <img src="projects/faces/cover/Gabrielitaa7x.jpg" class="coverimg hidden">
  <div class="desctitle">Gabrielitaa7x</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/Gabrielitaa7x.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="hamidmansoor123">
  <img src="projects/faces/cover/hamidmansoor123.jpg" class="coverimg hidden">
  <div class="desctitle">hamidmansoor123</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/hamidmansoor123.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="HawaiianAnn">
  <img src="projects/faces/cover/HawaiianAnn.jpg" class="coverimg hidden">
  <div class="desctitle">HawaiianAnn</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/HawaiianAnn.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="Jaclyn_Donahue_">
  <img src="projects/faces/cover/Jaclyn_Donahue_.jpg" class="coverimg hidden">
  <div class="desctitle">Jaclyn_Donahue_</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/Jaclyn_Donahue_.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="JoshuaSpence88">
  <img src="projects/faces/cover/JoshuaSpence88.jpg" class="coverimg hidden">
  <div class="desctitle">JoshuaSpence88</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/JoshuaSpence88.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="khaledbakri7">
  <img src="projects/faces/cover/khaledbakri7.jpg" class="coverimg hidden">
  <div class="desctitle">khaledbakri7</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/khaledbakri7.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="komarova6969">
  <img src="projects/faces/cover/komarova6969.jpg" class="coverimg hidden">
  <div class="desctitle">komarova6969</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/komarova6969.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="Lizzy17127377">
  <img src="projects/faces/cover/Lizzy17127377.jpg" class="coverimg hidden">
  <div class="desctitle">Lizzy17127377</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/Lizzy17127377.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="maksimkovalev15">
  <img src="projects/faces/cover/maksimkovalev15.jpg" class="coverimg hidden">
  <div class="desctitle">maksimkovalev15</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/maksimkovalev15.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="mihailkuznetzo1">
  <img src="projects/faces/cover/mihailkuznetzo1.jpg" class="coverimg hidden">
  <div class="desctitle">mihailkuznetzo1</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/mihailkuznetzo1.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="Sarah_Giaco">
  <img src="projects/faces/cover/Sarah_Giaco.jpg" class="coverimg hidden">
  <div class="desctitle">Sarah_Giaco</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/Sarah_Giaco.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="TinaTkurtz1222">
  <img src="projects/faces/cover/TinaTkurtz1222.jpg" class="coverimg hidden">
  <div class="desctitle">TinaTkurtz1222</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/TinaTkurtz1222.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="whoareyou765">
  <img src="projects/faces/cover/whoareyou765.jpg" class="coverimg hidden">
  <div class="desctitle">whoareyou765</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/whoareyou765.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="DaDanielDaDa">
  <img src="projects/faces/cover/DaDanielDaDa.jpg" class="coverimg hidden">
  <div class="desctitle">DaDanielDaDa</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/DaDanielDaDa.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="DmitriBelov12">
  <img src="projects/faces/cover/DmitriBelov12.jpg" class="coverimg hidden">
  <div class="desctitle">DmitriBelov12</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/DmitriBelov12.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="Kaliyah_Rrs">
  <img src="projects/faces/cover/Kaliyah_Rrs.jpg" class="coverimg hidden">
  <div class="desctitle">Kaliyah_Rrs</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/Kaliyah_Rrs.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="MelissaYesIam">
  <img src="projects/faces/cover/MelissaYesIam.jpg" class="coverimg hidden">
  <div class="desctitle">MelissaYesIam</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/MelissaYesIam.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="Uliabelushiva">
  <img src="projects/faces/cover/Uliabelushiva.jpg" class="coverimg hidden">
  <div class="desctitle">Uliabelushiva</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/Uliabelushiva.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>


<div class="project digital portraits faces" id="chalizzTrT">
  <img src="projects/faces/cover/chalizzTrT.jpg" class="coverimg hidden">
  <div class="desctitle">chalizzTrT</div>
  <div class="descmedia">Digital</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/faces/768/chalizzTrT.jpg" class="image notwide">
    <div class="image notwide">
 The series, titled "Portraits of Imaginary People" explores the latent space of human faces by training a neural network to imagine and then depict portraits of people who don&rsquo;t exist.

 To do so, many thousands of photographs of faces taken from Flickr are fed to a type of machine-learning program called a Generative Adversarial Network (GAN). GANs work by using two neural networks that play an adversarial game: one (the "Generator") tries to generate increasingly convincing output, while a second (the "Discriminator") tries to learn to distinguish real photos from the artificially generated ones.
 At first, both networks are poor at their respective tasks. But as the Discriminator network starts to learn to predict fake from real, it keeps the Generator on its toes, pushing it to generate harder and more convincing examples. In order to keep up, the Generator gets better and better, and the Discriminator correspondingly has to improve its response. With time, the images generated become increasingly realistic, as both adversaries try to outwit each other. The images you see here are thus a result of the rules and internal correlations the neural networks learned from the training images.
		</div>
    <hr>
  </div>
</div>





<!-- SCULPTURE -->

<div class="project sculpture" id="dopamine">
  <img src="projects/sculpture/dopamine.jpg" class="coverimg hidden">
  <div class="desctitle">Dopamine</div>
  <div class="descmedia">Plaster of Paris, Mirror, Dollar bill</div>
  <div class="descyear">2017</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/sculpture/dopamine.jpg" class="image wide">
    <hr>
  </div>
</div>

<div class="project sculpture" id="thesap">
  <img src="projects/sculpture/thesap.jpg" class="coverimg hidden">
  <div class="desctitle">Harvesting the Sap</div>
  <div class="descmedia">Cast lead glass, machined bronze</div>
  <div class="descyear">2018</div>
  <div class="desctext"></div>
  <div class="imagebox">
    <hr>
    <img data-src="projects/sculpture/thesap1.jpg" class="image">
    <img data-src="projects/sculpture/thesap2.jpg" class="image">
    <hr>
  </div>
</div>



<!-- COLLABORATIONS -->

<div class="project collaborations installation " id="groovikscube" >
  <img src="projects/groovikscube.jpg" class="coverimg hidden">
  <div class="desctitle">Groovik&rsquo;s Cube</div>
  <div class="descyear">2009-2014<br>Burning Man & Libery Science Center, NJ</div>
  <div class="desctext">
    <i><b>Groovik&rsquo;s Cube</b></i> is a fully playable, 35ft-high sculpture inspired by the classic puzzle, Rubik&rsquo;s Cube. It was built by Mike Tyka, Barry Brumitt and a team of artists and engineers from Seattle in 2009. It is, to our knowledge, the largest functional Rubik&rsquo;s Cube structure in the world. Groovik&rsquo;s Cube is controlled from 3 control stations that surround the main structure - each player is able to rotate only one axis, creating an entirely new, collaborative puzzle solving experience.
    <i><b>Groovik&rsquo;s Cube</b></i> offers a unique new playing mode where three players must collaborate to solve the classic Rubik&rsquo;s cube puzzle. The cube is controlled via three touch screen interfaces located around the cube, with each interface capable of rotating only one axis of the cube - no single player can solve the cube alone. This innovative twist adds a completely new dimension to the game and turns the classic puzzle into a social game and a fascinating social spectacle.
    <i><b>Groovik&rsquo;s Cube</b></i> is built from a lightweight aluminum frame, covered in fabric, and illuminated from the inside by 2 kilowatts of high-power LEDs. It simulates the motion of an ordinary Rubik&rsquo;s Cube by animating the rotations on the 54 &quot;pixels&quot; that comprise the cube. The total weight of the structure is around 2000 lbs and is designed such that participants may walk safely under the structure. The thin supports are virtually invisible from a distance, creating the magical illusion of a floating cube.
  </div>
  <div class="imagebox">
   <hr>
   <img data-src="projects/groovikscube/cube15_big.jpg" class="image wide">
   <img data-src="projects/groovikscube/cube4_big.jpg" class="image">
   <img data-src="projects/groovikscube/cube1_big.jpg" class="image">
   <img data-src="projects/groovikscube/groovelsc_1.jpg" class="image wide">
   <img data-src="projects/groovikscube/cube0_big.jpg" class="image">
   <img data-src="projects/groovikscube/cube2_big.jpg" class="image">
   <img data-src="projects/groovikscube/cube11_big.jpg" class="image">
   <img data-src="projects/groovikscube/cube7_big.jpg" class="image">
   <img data-src="projects/groovikscube/cube8_big.jpg" class="image">
   <img data-src="projects/groovikscube/cube9_big.jpg" class="image">
   <img data-src="projects/groovikscube/cube10_big.jpg" class="image">
   <img data-src="projects/groovikscube/cube14_big.jpg" class="image">
   <img data-src="projects/groovikscube/groovelsc_0.jpg" class="image">
     <hr>
  </div>
  <div class="videobox">
    <iframe class="image" height="500px" src="https://www.youtube.com/embed/PyYiMzpb67I?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen></iframe>
    <iframe class="image" height="500px" src="https://www.youtube.com/embed/6qOVOou13mY?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen></iframe>
  </div>
  <hr>
</div>

<div class="project collaborations performance" id="privacy">
  <img src="projects/privacy.jpg" class="coverimg hidden">
  <div class="desctitle">Privacy Dinner</div>
  <div class="descmedia">With Allegra Searle-LeBel and Maxime Billet</div>
  <div class="descyear">2015</div>
  <div class="desctext">
  </div>
  <div class="imagebox">
    <img data-src="projects/privacy/10.jpg" class="image">
    <img data-src="projects/privacy/17.jpg" class="image">
    <img data-src="projects/privacy/22.jpg" class="image">
    <img data-src="projects/privacy/24.jpg" class="image">
    <img data-src="projects/privacy/28.jpg" class="image">
    <img data-src="projects/privacy/31.jpg" class="image">
    <img data-src="projects/privacy/34.jpg" class="image">
    <img data-src="projects/privacy/45.jpg" class="image">
  </div>
</div>

<div class="project collaborations performance" id="butoh">
  <img src="projects/butoh.jpg" class="coverimg hidden">
  <div class="desctitle">Beyond the Metaphors</div>
  <div class="descmedia">With Kaoru Okumura and Robin Buerki</div>
  <div class="descyear">2016</div>
  <div class="desctext">
    Butoh dancer Kaoru Okomura and Mike Tyka collaborated on a performance for the Seattle Butoh Festival and the <a href="www.9e2seattle.com">Seattle 9e2 event</a> The piece combines the intensity of Butoh with the strange and wonderful nature of the DeepDream algorithm.
  <br><br>
     The artists first experimented with wall projections, but the white attire and makeup of Butoh suggested an opportunity to project directly onto the dancers bodies. To obtain a stable projected image, the artists rigged a projector with a Kinect sensor and a steady cam. After conducting several experiments, Okumura and Tyka chose flora and fauna themes as the entry point for artistic dialogue - reminiscent perhaps of ancient evolutionary remnants in our human selves.
  <br>
	<center><iframe width="560" height="315" src="https://www.youtube.com/embed/ILeSdTXgzys?start=164" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></center>
	<br>
      DeepDream and Butoh are both human reactions to changing technological circumstances. But they sit in uneasy harmony, with the minimalist, organic, and very human dance form finding an odd partner in the nonlinear hallucinations of machines. In this collaboration the two media reflect the challenge of balancing our animal selves with the technology rising around us, and suggest that human responses to technology must be creative, adaptive, and sometimes shockingly novel.
  </div>
  <div class="imagebox">
    <img data-src="projects/butoh/_MG_6387.jpg" class="image">
    <img data-src="projects/butoh/_MG_6265.jpg" class="image">
    <img data-src="projects/butoh/_MG_6286.jpg" class="image">
    <img data-src="projects/butoh/_MG_6397.jpg" class="image">
    <img data-src="projects/butoh/_MG_6415.jpg" class="image">
    <img data-src="projects/butoh/_MG_6455.jpg" class="image">
  </div>
</div>

<div class="project collaborations netart" id="blingee">
  <img src="projects/blingee.jpg" class="coverimg hidden">
  <div class="desctitle">Big Glitter</div>
  <div class="descmedia">Net art with Olia Lialina</div>
  <div class="descyear">2017</div>
  <div class="desctext">
    <hr>
    Netart work in collaboration <a href="https://lialina-tyka.art/">with Olia Lialina for Rhizome&#39;s 7x7 in NYC, 2017</a>
    <br><br>
    Original artwok: <a href="http://blingee.geocities.institute/">http://blingee.geocities.institute/</a>
    <br><br>
    <b>*Once again to IVK*<br></b>
    <a href="http://blingee.geocities.institute/staying_in_ivk.html">staying with IVK</a> --paths through blingees that let&#39;s you stay in the universe of stamps made by one user.<br>
    <a href="http://blingee.geocities.institute/trajectory_goingaway.html">away from IVK</a> -- paths that les you go<br><br>

    <b>*Turing test, reversed and sparkling*</b>
    <a href="http://www.miketyka.com/blingee/round3/">are they human?</a>
    <br><br>

    <b>*Treasure trove*</b>
    <a href="/treasure_trove/">440 blingee diamonds</a> expropriated from Blingee.com, made ready to be used outside of the service.
    (<a href="/treasure_trove/screenshots/">screenshots</a>, <a href="https://www.youtube.com/watch?v=8iJriJlsh78">videocast</a>)<br><br>
    <hr>
    <b>Press:</b>
    <ul>
     <li><a href="http://nymag.com/selectall/2017/04/fending-off-the-apocalypse-with-blingee-art.html">NyMag: Fending Off the Apocalypse With Blingee Art</a></li>
     <li><a href="https://art.art/news/bringing-artists-technologists-together-sevenonseven-art/">Art.Art: Bringing Artists and Technologists Together: sevenonseven.art</a></li>
     <li><a href="http://www.artnews.com/2017/04/24/at-seven-on-seven-conference-artists-and-technologists-unite-to-ponder-politics-sexting-fake-news-and-more/">ArtNews: Artists and Technologists Unite to Ponder Politics, Sexting, Fake News, and More</a></li>
   </ul>
   <hr>
 </div>
 <div class="imagebox">
  <div class="image">
   <img data-src="projects/blingee/1492887912722442.jpg" class="image wide">
   <img data-src="projects/blingee/stage.jpg" class="image wide">
   <iframe class="image wide" height="415" src="https://www.youtube.com/embed/53DfLENm-Fs" frameborder="0" allowfullscreen></iframe>
  </div><div class="image">
   <img data-src="projects/blingee/part2.jpg" class="image wide">
   <img data-src="projects/blingee/part3.jpg" class="image wide">
   <iframe class="image wide" height="415" src="https://www.youtube.com/embed/8iJriJlsh78" frameborder="0" allowfullscreen></iframe>
  </div>
</div>
</div>


<div class="project collaborations installation" id="salt">
  <img src="projects/salt.jpg" class="coverimg hidden">
  <div class="desctitle">Archive Dreaming</div>
  <div class="descmedia">Installation with <a href="http://www.refikanadol.com" target="_blank">Refik Anadol</a></div>
  <div class="descyear">2017</div>
  <div class="desctext">
    Archive Dreaming is a collaboration with Refik Anadol, who was commissioned to work with SALT Research collections an archive of 1,700,000 historical documents. Shortly after receiving the commission, Anadol was a resident artist for Google&#39;s Artists and Machine Intelligence Program where he closely collaborated with Mike Tyka and explored cutting-edge developments in the field of machine intelligence in an environment that brings together artists and engineers. Developed during this residency, his intervention Archive Dreaming transforms the gallery space on floor -1 at SALT Galata into an all-encompassing environment that intertwines history with the contemporary, and challenges immutable concepts of the archive, while destabilizing archive-related questions with machine learning algorithms.
    <br><br>
    In this project, a temporary immersive architectural space is created as a canvas with light and data applied as materials. This radical effort to deconstruct the framework of an illusory space will transgress the normal boundaries of the viewing experience of a library and the conventional flat cinema projection screen, into a three dimensional kinetic and architectonic space of an archive visualized with machine learning algorithms. By training a neural network with images of 1,700,000 documents at SALT Research the main idea is to create an immersive installation with architectural intelligence to reframe memory, history and culture in museum perception for 21st century through the lens of machine intelligence.
    <br><br>
    Archive Dreaming is one of the first ever large-scale art installations to use "Generative Adversarial Networks" to "dream" imaginary representations based on a large corpus of images.
  </div>
  <div class="imagebox">
    <img data-src="projects/salt/000-1880x1125.jpg" class="image">
    <img data-src="projects/salt/019-1880x1125.jpg" class="image">

    <hr>
    <img data-src="projects/salt/03-1880x2155.jpg" class="image">
    <img data-src="projects/salt/1.7.tsne.jpg" class="image">

    <hr>
    <img data-src="projects/salt/170-1880x1125.jpg" class="image">
    <img data-src="projects/salt/240-1880x1125.jpg" class="image">

    <img data-src="projects/salt/080-1880x1125.jpg" class="image">
    <img data-src="projects/salt/250-1880x1125.jpg" class="image">

    <hr>
    <img data-src="projects/salt/all.256.jpg" class="image">
    <img data-src="projects/salt/enriched_goodpack_withcolor.jpg" class="image">

    <hr>
    <img data-src="projects/salt/niceone.jpg" class="image">
    <img data-src="projects/salt/test512.jpg" class="image">
    <hr>
  </div>
</div>


<div class="project" id="bio" >
 <hr>
 <p>
Mike Tyka studied Biochemistry and Biotechnology at the University of Bristol. He obtained his PhD in Biophysics in 2007 and went on to work as a research fellow at the University of Washington to study the structure and dynamics of protein molecules. In particular, he has been interested in protein folding and has been writing computer simulation software to better understand this fascinating process. Mike joined Google in 2012 and worked on creating a neuron-level map of fly and mouse brain tissue using computer vision and machine learning. 
 </p>

 <p>
Mike became involved in creating sculpture and art in 2009 when he helped design and construct <a href="http://www.miketyka.com/?p=groovikscube">Groovik&#39;s Cube</a>, a 35ft tall, functional, multi-player Rubik's cube installed in Reno, Seattle and New York. Since then his artistic work has focused both on traditional sculpture and modern technology, such as 3D printing and artificial neural networks.
His <a href="http://www.miketyka.com/?s=molecule">sculptures of protein molecules</a> use cast glass and bronze and are based on the exact molecular coordinates of each respective biomolecule. They explore the hidden beauty of these amazing nanomachines, and have been shown around the world from Seattle to Japan. </p>

 <p>
Mike also works with artificial neural networks as an artistic medium and tool. In 2015 created some of the first large-scale artworks using <a href="http://www.miketyka.com/?s=deepdream">Iterative DeepDream</a> and co-founded the <a href="http://g.co/ami">Artists and Machine Intelligence program at Google</a>. In 2017 he collaborated with Refik Anadol to create a pioneering immersive projection installation using Generative Adversarial Networks called <a href="http://www.miketyka.com/?p=salt">"Archive Dreaming"</a>. His latest generative series "Portraits of Imaginary People" has been shown at ARS Electronica in Linz, Christie's in New York and at the New Museum in Karuizawa (Japan). His kinetic, AI-driven sculpture "Us and Them" was featured at the 2018 Mediacity Biennale at the Seoul Museum of Art.
 </p>


 For more information or availablility of the pieces contact him at:
 <p>
 Email: mike.tyka@gmail.com
 </p>
 <div>
  <hr>
  <img src="pics/mike.jpg">
  <hr>
</div>
<p>
   <b>Art Exhibitions/Installations</b>
   <ul>
     <li><a href="https://www.bellevuearts.org/exhibitions/past/bam-biennial-2018">2018 BAM! Glasstastic, Bellevue Arts Museum, Seattle, "Harvesting the Sap"</a></li>
     <li><a href="http://mediacityseoul.kr/">2018 Mediacity Biennale, Seoul Museum of Art, Seoul, "Us and Them"</a></li>
     <li><a href="http://aloalo.co.jp/nakazawa/2017/aiaae.html">2017 OIST, Okinawa, "Art and AI Aethetics" exhibition, Three Deep Dreams</a></li>
     <li><a href="http://knam.jp/exhibitions/2017/%E3%82%A2%E3%83%BC%E3%83%88%E3%81%AF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E2%85%A1%E3%80%80%EF%BC%8Dart-is-science%E2%85%A1-%EF%BC%8D/">2017 Karuizawa New Museum, Karuizawa, "Art is Science II"</a></li>
     <li><a href="https://www.aec.at/ai/en/portraits-of-imaginary-people/">2017 ARS Electronica, Portraits of Imaginary People</a></li>
     <li><a href="http://www.outofsight.space/">2017 OutOfSight, Group Show: Portraits of Imaginary People</a></li>
     <li><a href="http://saltonline.org/en/1627/archive-dreaming">2017 SALT Institute, Istanbul, Archive dreaming (with Refik Anadol)</a></li>

		 <li><a href="http://www.9e2seattle.org/">2016 9evenings2, Seattle, Group Show, Molecular sculpture</a></li>
     <li><a href="http://www.9e2seattle.org/">2016 9evenings2, Seattle, Live Performance "Butoh vs DeepDream"</a></li>
     <li><a href="https://grayarea.org/press/inside-googles-first-deepdream-art-show/">2015 Grey Area Art Foundation, San Francisco,  "The art of neural networks"</a></li>
     <li>2014-2016 Fred Hutch Cancer Institute. Semi-permanent installation "Savior" and "Portal"</li>
     <li><a href="https://lsc.org/news-and-social/news/the-original-grooviks-cube">2013 Liberty Science Center, New Jersey,  "Groovik's Cube III" </a></li>
     <li>2011 Pacific Science Center, Seattle,  "Groovik's Cube II" </li>
     <li>2009 Black Rock City, Nevada,  "Groovik's Cube" </li>
   </ul>

   <b>Invited Talks</b>
   <ul>
     <li><a href="http://aloalo.co.jp/nakazawa/2017/aiaae07_symposium.png">2017 OIST, Okohama, "Art and AI Aethetics" symposium</a></li>
     <li>2017 Tokyo, Digital Hollywood University</li>
     <li><a href="http://genekogan.com/alt-AI/">2016 Alt-Ai Conference, New York</a></li>
     <li><a href="http://dijitaldevrim.zorlupsm.com/digi-logue/">2016 Digi.Logue, Istanbul</a></li>
     <li><a href="https://design.google.com/span-2016-tokyo/">2016 Google SPAN Tokyo</a></li>
     <li><a href="https://magenta.tensorflow.org/welcome-to-magenta">2016 Magenta Conference</a></li>
     <li>2016 Google Cultural Institute Summit, Paris</li>
     <li><a href="https://research-142105.googleplex.com/static/index.html">2016 Research at Google conference</a></li>
     <li><a href="http://bcnm.berkeley.edu/2016/12/07/mike-tyka-atc-video-now-online">2016 UC Berkley Center for New Media</a></li>
     <li><a href="https://www.youtube.com/watch?v=0qVOUD76JOg">2015 TEDx Munich</a></li>
     <li><a href="">2012 Google IO, Invited speaker for Ignite talk.</a></li>
     <li><a href="">2011 SciFoo, Mountain View, Invited speaker</a></li>
     <li><a href="">2010 FooCamp, O'Reilly Media. Invited speaker for Ignite talk.</a></li>
     <li><a href="">2007 CCPB Biomolecular Simulation</a></li>
   </ul>
   <br>
</div>

<div class="project" id="contact" >
 <hr>
 Email: mike.tyka@gmail.com <br>
 Twitter: <a href="https://www.twitter.com/mtyka">@mtyka</a><br>
 Instagram: <a href="https://www.instagram.com/miketyka">[miketyka]</a>
 <hr>
</div>

<div class="project topmenu" id="molecule">
  <div class="crop">
    <img class="image coverimg" src="projects/ubiquitin.jpg">
  </div>
  <div class="descmedia">Molecular Sculpture</div>
</div>

<div class="project topmenu" id="deepdream">
  <div class="crop">
    <img class="image coverimg" src="projects/neuralart.jpg">
  </div>
  <div class="descmedia">AI: Deepdream</div>
</div>

<div class="project topmenu" id="faces">
  <div class="crop">
    <img class="image coverimg" src="projects/faces.jpg">
  </div>
  <div class="descmedia">AI: Generative Adversarial Networks</div>
</div>

<div class="project topmenu" id="sculpture">
  <div class="crop">
    <img class="image coverimg" src="projects/sculpture.jpg">
  </div>
  <div class="descmedia">Sculpture</div>
</div>

<div class="project topmenu" id="collaborations">
  <div class="crop">
    <img class="image coverimg" src="projects/groovikscube/cube15_big.jpg">
  </div>
  <div class="descmedia">Collaborations</div>
</div>
<!-- ======= ======= ======= ======= ======= ======= ======= ======= ======= ======= ======= ======= ======= ======= -->

</div>



<div class="hidden">
  <div id="defaultbox" class="box">
    <div class="crop">
      <img class="coverimg" src="">
    </div>
  </div>
</div>


</body>
</html>
